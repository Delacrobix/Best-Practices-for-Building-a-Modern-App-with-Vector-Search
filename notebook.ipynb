{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Best Practices for Building a Modern App with Vector Search\n",
    "\n",
    "This notebook demonstrates how to build a modern LLM-powered application using:\n",
    "\n",
    "- **Jina Embeddings v3** via Elastic Inference Service (EIS) - GPU-accelerated multilingual embeddings\n",
    "- **Elasticsearch 9.3+** for vector storage and semantic search\n",
    "- **Agent Builder** for creating AI agents that can query your data\n",
    "\n",
    "## What You'll Learn\n",
    "\n",
    "1. Setting up inference endpoints for embeddings\n",
    "2. Creating optimized indices for vector search\n",
    "3. Ingesting data with automatic embedding generation\n",
    "4. Performing semantic searches\n",
    "5. Building an AI agent with Agent Builder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.3\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m26.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Install required packages\n",
    "!pip install elasticsearch requests dotenv -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import requests\n",
    "from elasticsearch import Elasticsearch\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# Elasticsearch configuration\n",
    "ELASTICSEARCH_URL = os.getenv(\"ELASTICSEARCH_URL\")\n",
    "ELASTIC_API_KEY = os.getenv(\"ELASTICSEARCH_API_KEY\")\n",
    "KIBANA_URL = os.getenv(\"KIBANA_URL\")\n",
    "\n",
    "# Initialize Elasticsearch client\n",
    "es = Elasticsearch(ELASTICSEARCH_URL, api_key=ELASTIC_API_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Inference Endpoint for Embeddings\n",
    "\n",
    "We'll use **Jina Embeddings v3** through Elastic Inference Service (EIS). This model:\n",
    "\n",
    "- Is multilingual out of the box\n",
    "- Runs on Elastic's GPU infrastructure (no ML nodes needed)\n",
    "\n",
    "### Best Practice: Use EIS for Production Workloads\n",
    "EIS eliminates the need to manage ML infrastructure while providing GPU-accelerated performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Connection timed out\n"
     ]
    }
   ],
   "source": [
    "INFERENCE_ENDPOINT_ID = \"jina-embeddings-v3\"\n",
    "\n",
    "# Create the inference endpoint for Jina Embeddings v3\n",
    "inference_config = {\n",
    "    \"service\": \"elastic\",\n",
    "    \"service_settings\": {\"model_id\": \"jina-embeddings-v3\"},\n",
    "}\n",
    "\n",
    "try:\n",
    "    response = es.inference.put(\n",
    "        inference_id=INFERENCE_ENDPOINT_ID,\n",
    "        task_type=\"text_embedding\",\n",
    "        body=inference_config,\n",
    "    )\n",
    "\n",
    "    print(f\"Created inference endpoint: {INFERENCE_ENDPOINT_ID}\")\n",
    "    print(json.dumps(response.body, indent=2))\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding dimensions: 1024\n",
      "First 5 values: [0.09668593, -0.0195286, 0.03599555, -0.04717219, 0.07873663]\n"
     ]
    }
   ],
   "source": [
    "# Test the inference endpoint\n",
    "test_response = es.inference.inference(\n",
    "    inference_id=INFERENCE_ENDPOINT_ID,\n",
    "    body={\n",
    "        \"input\": \"Elasticsearch is a distributed search and analytics engine.\",\n",
    "        \"input_type\": \"ingest\",\n",
    "    },\n",
    ")\n",
    "\n",
    "embedding = test_response.body[\"text_embedding\"][0][\"embedding\"]\n",
    "print(f\"Embedding dimensions: {len(embedding)}\")\n",
    "print(f\"First 5 values: {embedding[:5]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create an Optimized Index for Vector Search\n",
    "\n",
    "### Best Practices for Index Design:\n",
    "1. **Use `semantic_text` field type** - Automatically handles chunking and embedding generation\n",
    "2. **Use `copy_to` pattern** - Keep original fields for BM25 and copy content to a dedicated semantic field\n",
    "3. **Consider field lengths** - Jina v3 performs optimally with 2048-4096 tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index 'tech-articles' already exists, skipping creation\n"
     ]
    }
   ],
   "source": [
    "INDEX_NAME = \"tech-articles\"\n",
    "\n",
    "# Create index with semantic_text field using copy_to pattern\n",
    "# Best Practice: Keep original fields for BM25 search and use copy_to for semantic search\n",
    "index_mappings = {\n",
    "    \"mappings\": {\n",
    "        \"properties\": {\n",
    "            \"title\": {\"type\": \"text\", \"copy_to\": \"semantic_field\"},\n",
    "            \"content\": {\"type\": \"text\", \"copy_to\": \"semantic_field\"},\n",
    "            \"category\": {\"type\": \"keyword\"},\n",
    "            \"published_date\": {\"type\": \"date\"},\n",
    "            \"semantic_field\": {\n",
    "                \"type\": \"semantic_text\",\n",
    "                \"inference_id\": INFERENCE_ENDPOINT_ID,\n",
    "            },\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# Only create the index if it doesn't exist\n",
    "if not es.indices.exists(index=INDEX_NAME):\n",
    "    response = es.indices.create(index=INDEX_NAME, body=index_mappings)\n",
    "    print(f\"Created index: {INDEX_NAME}\")\n",
    "    print(json.dumps(response.body, indent=2))\n",
    "else:\n",
    "    print(f\"Index '{INDEX_NAME}' already exists, skipping creation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ingest Sample Data\n",
    "\n",
    "### Best Practice: Use Bulk Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 documents indexed successfully\n"
     ]
    }
   ],
   "source": [
    "from elasticsearch import helpers\n",
    "\n",
    "\n",
    "def build_data(json_file, index_name):\n",
    "    \"\"\"Generator function to yield documents for bulk indexing.\"\"\"\n",
    "    with open(json_file, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    for doc in data:\n",
    "        yield {\"_index\": index_name, \"_source\": doc}\n",
    "\n",
    "\n",
    "# Bulk index the documents from JSON file\n",
    "try:\n",
    "    success, failed = helpers.bulk(\n",
    "        es,\n",
    "        build_data(\"dataset.json\", INDEX_NAME),\n",
    "    )\n",
    "    print(f\"{success} documents indexed successfully\")\n",
    "\n",
    "    if failed:\n",
    "        print(f\"Errors: {failed}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total documents in index: 5\n"
     ]
    }
   ],
   "source": [
    "# Check document count\n",
    "count = es.count(index=INDEX_NAME)\n",
    "print(f\"Total documents in index: {count.body['count']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Semantic Search\n",
    "\n",
    "### Best Practice: Use `match` Query on `semantic_text` Fields\n",
    "The `match` query automatically detects `semantic_text` fields and handles embedding generation for your search query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def semantic_search(query: str, size: int = 3):\n",
    "    \"\"\"Perform semantic search on the tech-articles index.\"\"\"\n",
    "    response = es.search(\n",
    "        index=INDEX_NAME,\n",
    "        body={\n",
    "            \"query\": {\"match\": {\"semantic_field\": {\"query\": query}}},\n",
    "            \"size\": size,\n",
    "            \"_source\": [\"title\", \"category\", \"content\"],\n",
    "        },\n",
    "    )\n",
    "\n",
    "    print(f\"Query: '{query}'\\n\")\n",
    "    print(f\"Found {response.body['hits']['total']['value']} results:\\n\")\n",
    "\n",
    "    for hit in response.body[\"hits\"][\"hits\"]:\n",
    "        print(f\"Score: {hit['_score']:.4f}\")\n",
    "        print(f\"Title: {hit['_source']['title']}\")\n",
    "        print(f\"Category: {hit['_source']['category']}\")\n",
    "        print(f\"Content: {hit['_source']['content'][:150]}...\\n\")\n",
    "\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: 'How do I implement similarity search in my application?'\n",
      "\n",
      "Found 5 results:\n",
      "\n",
      "Score: 0.6704\n",
      "Title: Introduction to Vector Databases\n",
      "Category: databases\n",
      "Content: Vector databases are specialized systems designed to store and query high-dimensional vectors efficiently. They enable similarity search, which is fun...\n",
      "\n",
      "Score: 0.6694\n",
      "Title: Building RAG Applications with Elasticsearch\n",
      "Category: ai\n",
      "Content: Retrieval-Augmented Generation (RAG) combines the power of large language models with external knowledge retrieval. Elasticsearch provides an excellen...\n",
      "\n",
      "Score: 0.6445\n",
      "Title: Embeddings: The Foundation of Semantic Search\n",
      "Category: ai\n",
      "Content: Embeddings are numerical representations of text that capture semantic meaning. Modern embedding models like Jina v3 can process text in multiple lang...\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ObjectApiResponse({'took': 209, 'timed_out': False, '_shards': {'total': 1, 'successful': 1, 'skipped': 0, 'failed': 0}, 'hits': {'total': {'value': 5, 'relation': 'eq'}, 'max_score': 0.67035043, 'hits': [{'_index': 'tech-articles', '_id': 'oyBuNJwBTUn0vNv4PgWW', '_score': 0.67035043, '_source': {'title': 'Introduction to Vector Databases', 'content': 'Vector databases are specialized systems designed to store and query high-dimensional vectors efficiently. They enable similarity search, which is fundamental for AI applications like recommendation systems, image search, and semantic text search. Unlike traditional databases that use exact matching, vector databases find the most similar items based on distance metrics like cosine similarity or Euclidean distance.', 'category': 'databases'}}, {'_index': 'tech-articles', '_id': 'pCBuNJwBTUn0vNv4PgWW', '_score': 0.6693985, '_source': {'title': 'Building RAG Applications with Elasticsearch', 'content': 'Retrieval-Augmented Generation (RAG) combines the power of large language models with external knowledge retrieval. Elasticsearch provides an excellent foundation for RAG applications by offering hybrid search capabilities that combine traditional BM25 text matching with semantic vector search. This hybrid approach ensures both keyword relevance and semantic understanding in your search results.', 'category': 'ai'}}, {'_index': 'tech-articles', '_id': 'pSBuNJwBTUn0vNv4PgWW', '_score': 0.64447546, '_source': {'title': 'Embeddings: The Foundation of Semantic Search', 'content': 'Embeddings are numerical representations of text that capture semantic meaning. Modern embedding models like Jina v3 can process text in multiple languages and produce high-quality vectors that preserve semantic relationships. The key to effective semantic search is choosing the right embedding model for your use case and ensuring your text is properly preprocessed before embedding generation.', 'category': 'ai'}}]}})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test semantic search\n",
    "semantic_search(\"How do I implement similarity search in my application?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hybrid Search (BM25 + Semantic)\n",
    "\n",
    "### Best Practice: Combine Lexical and Semantic Search\n",
    "Hybrid search gives you the best of both worlds - exact keyword matching and semantic understanding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hybrid_search(query: str, size: int = 3):\n",
    "    \"\"\"Perform hybrid search combining BM25 and semantic search.\"\"\"\n",
    "    response = es.search(\n",
    "        index=INDEX_NAME,\n",
    "        body={\n",
    "            \"retriever\": {\n",
    "                \"rrf\": {\n",
    "                    \"retrievers\": [\n",
    "                        {\n",
    "                            \"standard\": {\n",
    "                                \"query\": {\n",
    "                                    \"multi_match\": {\n",
    "                                        \"query\": query,\n",
    "                                        \"fields\": [\n",
    "                                            \"title^2\",\n",
    "                                            \"content\",\n",
    "                                        ],  # BM25 on original text fields\n",
    "                                    }\n",
    "                                }\n",
    "                            }\n",
    "                        },\n",
    "                        {\n",
    "                            \"standard\": {\n",
    "                                \"query\": {\"match\": {\"semantic_field\": {\"query\": query}}}\n",
    "                            }\n",
    "                        },\n",
    "                    ],\n",
    "                    \"rank_window_size\": 50,\n",
    "                    \"rank_constant\": 20,\n",
    "                }\n",
    "            },\n",
    "            \"size\": size,\n",
    "            \"_source\": [\"title\", \"category\"],\n",
    "        },\n",
    "    )\n",
    "\n",
    "    print(f\"Hybrid Search Query: '{query}'\\n\")\n",
    "\n",
    "    for hit in response.body[\"hits\"][\"hits\"]:\n",
    "        print(\n",
    "            f\"Score: {hit['_score']:.4f} | {hit['_source']['title']} [{hit['_source']['category']}]\"\n",
    "        )\n",
    "\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hybrid Search Query: 'What are the best practices for semantic search in Elasticsearch?'\n",
      "\n",
      "Score: 0.0931 | Scaling Elasticsearch for Production [infrastructure]\n",
      "Score: 0.0893 | Embeddings: The Foundation of Semantic Search [ai]\n",
      "Score: 0.0889 | Building RAG Applications with Elasticsearch [ai]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ObjectApiResponse({'took': 289, 'timed_out': False, '_shards': {'total': 1, 'successful': 1, 'skipped': 0, 'failed': 0}, 'hits': {'total': {'value': 5, 'relation': 'eq'}, 'max_score': 0.09307359, 'hits': [{'_index': 'tech-articles', '_id': 'piBuNJwBTUn0vNv4PgWW', '_score': 0.09307359, '_source': {'title': 'Scaling Elasticsearch for Production', 'category': 'infrastructure'}}, {'_index': 'tech-articles', '_id': 'pSBuNJwBTUn0vNv4PgWW', '_score': 0.08928572, '_source': {'title': 'Embeddings: The Foundation of Semantic Search', 'category': 'ai'}}, {'_index': 'tech-articles', '_id': 'pCBuNJwBTUn0vNv4PgWW', '_score': 0.08893281, '_source': {'title': 'Building RAG Applications with Elasticsearch', 'category': 'ai'}}]}})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hybrid_search(\"What are the best practices for semantic search in Elasticsearch?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create an AI Agent with Agent Builder\n",
    "\n",
    "Agent Builder uses LLMs to power agent reasoning and decision-making.\n",
    "\n",
    "### Default vs Custom LLM\n",
    "- **Elastic Managed LLM** (default): Available out-of-the-box on Elastic Cloud. No configuration or API keys needed.\n",
    "- **Custom LLM**: You can configure third-party providers (OpenAI, Azure, Anthropic, etc.) using connectors.\n",
    "\n",
    "### SSL Certificate Verification\n",
    "For production environments, use `verify=True` when making HTTPS requests:\n",
    "- **Elastic Cloud**: Certificates are valid by default, no additional configuration needed.\n",
    "- **Self-managed**: You may need to provide the CA certificate path (e.g., `verify=\"/path/to/ca.crt\"`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error creating agent: {\"statusCode\":400,\"error\":\"Bad Request\",\"message\":\"Agent with id tech-articles-assistant already exists\",\"attributes\":{}}\n"
     ]
    }
   ],
   "source": [
    "# Create an Agent using the default Elastic Managed LLM\n",
    "\n",
    "headers = {\n",
    "    \"kbn-xsrf\": \"true\",\n",
    "    \"Authorization\": f\"ApiKey {ELASTIC_API_KEY}\",\n",
    "    \"Content-Type\": \"application/json\",\n",
    "}\n",
    "\n",
    "agent_payload = {\n",
    "    \"id\": \"tech-articles-assistant\",\n",
    "    \"name\": \"Tech Articles Assistant\",\n",
    "    \"description\": \"An AI assistant that helps users find information about technology topics from our knowledge base.\",\n",
    "    \"configuration\": {\n",
    "        \"tools\": [{\"tool_ids\": [\"platform.core.search\", \"platform.core.execute_esql\"]}],\n",
    "        \"instructions\": f\"\"\"You are a helpful assistant that answers questions about technology topics.\n",
    "\n",
    "Use the search tool to find relevant articles from the '{INDEX_NAME}' index.\n",
    "When searching, prefer semantic search for natural language questions.\n",
    "Always cite the article titles when providing information.\n",
    "If you cannot find relevant information, say so clearly.\"\"\",\n",
    "    },\n",
    "}\n",
    "\n",
    "response = requests.post(\n",
    "    f\"{KIBANA_URL}/api/agent_builder/agents\",\n",
    "    headers=headers,\n",
    "    json=agent_payload,\n",
    "    verify=True,\n",
    ")\n",
    "\n",
    "if response.status_code == 200:\n",
    "    agent_data = response.json()\n",
    "    agent_id = agent_data.get(\"id\")\n",
    "    print(f\"Created agent: {agent_id}\")\n",
    "    print(json.dumps(agent_data, indent=2))\n",
    "else:\n",
    "    print(f\"Error creating agent: {response.text}\")\n",
    "    agent_id = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chat with the agent\n",
    "def chat_with_agent(agent_id: str, message: str):\n",
    "    \"\"\"Send a message to the agent and get a response.\"\"\"\n",
    "    chat_payload = {\"input\": message, \"agent_id\": agent_id}\n",
    "\n",
    "    response = requests.post(\n",
    "        f\"{KIBANA_URL}/api/agent_builder/converse\",\n",
    "        headers=headers,\n",
    "        json=chat_payload,\n",
    "        verify=True,\n",
    "    )\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        return response.json()\n",
    "    else:\n",
    "        return {\"error\": response.text, \"status_code\": response.status_code}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example conversation\n",
    "if agent_id:\n",
    "    result = chat_with_agent(\n",
    "        agent_id, \"What are the best practices for building RAG applications?\"\n",
    "    )\n",
    "    print(json.dumps(result, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# es.indices.delete(index=INDEX_NAME)\n",
    "# es.inference.delete(inference_id=INFERENCE_ENDPOINT_ID)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
