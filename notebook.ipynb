{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "afcb6423",
   "metadata": {},
   "source": [
    "# Best Practices for Building a Modern App with Vector Search\n",
    "\n",
    "This notebook demonstrates how to build a modern LLM-powered application using:\n",
    "\n",
    "- **Jina Embeddings v3** via Elastic Inference Service (EIS) - GPU-accelerated multilingual embeddings\n",
    "- **Elasticsearch 9.3+** for vector storage and semantic search\n",
    "- **Agent Builder** for creating AI agents that can query your data\n",
    "\n",
    "## What You'll Learn\n",
    "\n",
    "1. Setting up inference endpoints for embeddings\n",
    "2. Creating optimized indices for vector search\n",
    "3. Ingesting data with automatic embedding generation\n",
    "4. Performing semantic searches\n",
    "5. Building an AI agent with Agent Builder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a823c2a6",
   "metadata": {},
   "source": [
    "## Setup and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf2b3304",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install elasticsearch requests dotenv -q\n",
    "\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "299462c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "from elasticsearch import Elasticsearch\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# Elasticsearch configuration\n",
    "ELASTICSEARCH_URL = os.getenv(\"ELASTICSEARCH_URL\")\n",
    "ELASTIC_API_KEY = os.getenv(\"ELASTICSEARCH_API_KEY\")\n",
    "KIBANA_URL = os.getenv(\"KIBANA_URL\")\n",
    "\n",
    "# Initialize Elasticsearch client\n",
    "es = Elasticsearch(ELASTICSEARCH_URL, api_key=ELASTIC_API_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f97f5d35",
   "metadata": {},
   "source": [
    "## Create Inference Endpoint for Embeddings\n",
    "\n",
    "We'll use **Jina Embeddings v3** through Elastic Inference Service (EIS). This model:\n",
    "\n",
    "- Is multilingual out of the box\n",
    "- Runs on Elastic's GPU infrastructure (no ML nodes needed)\n",
    "\n",
    "### Best Practice: Use EIS for Production Workloads\n",
    "EIS eliminates the need to manage ML infrastructure while providing GPU-accelerated performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b021a45a",
   "metadata": {},
   "outputs": [],
   "source": [
    "INFERENCE_ENDPOINT_ID = \"embeddings-endpoint\"\n",
    "\n",
    "# Create the inference endpoint for Jina Embeddings v3\n",
    "inference_config = {\n",
    "    \"service\": \"elastic\",\n",
    "    \"service_settings\": {\"model_id\": \"jina-embeddings-v3\"},\n",
    "}\n",
    "\n",
    "try:\n",
    "    response = es.inference.put(\n",
    "        inference_id=INFERENCE_ENDPOINT_ID,\n",
    "        task_type=\"text_embedding\",\n",
    "        body=inference_config,\n",
    "    )\n",
    "\n",
    "    print(f\"Created inference endpoint: {INFERENCE_ENDPOINT_ID}\")\n",
    "    print(json.dumps(response.body, indent=2))\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97450ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the inference endpoint\n",
    "test_response = es.inference.inference(\n",
    "    inference_id=INFERENCE_ENDPOINT_ID,\n",
    "    body={\n",
    "        \"input\": \"Elasticsearch is a distributed search and analytics engine.\",\n",
    "        \"input_type\": \"ingest\",\n",
    "    },\n",
    ")\n",
    "\n",
    "embedding = test_response.body[\"text_embedding\"][0][\"embedding\"]\n",
    "print(f\"Embedding dimensions: {len(embedding)}\")\n",
    "print(f\"First 5 values: {embedding[:5]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd1078b3",
   "metadata": {},
   "source": [
    "## Create an Optimized Index for Vector Search\n",
    "\n",
    "### Best Practices for Index Design:\n",
    "1. **Use `semantic_text` field type** - Automatically handles chunking and embedding generation\n",
    "2. **Use `copy_to` pattern** - Keep original fields for BM25 and copy content to a dedicated semantic field\n",
    "3. **Consider field lengths** - Jina v3 performs optimally with 2048-4096 tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8300c47d",
   "metadata": {},
   "outputs": [],
   "source": [
    "INDEX_NAME = \"tech-articles\"\n",
    "\n",
    "# Create index with semantic_text field using copy_to pattern\n",
    "# Best Practice: Keep original fields for BM25 search and use copy_to for semantic search\n",
    "index_mappings = {\n",
    "    \"mappings\": {\n",
    "        \"properties\": {\n",
    "            \"title\": {\"type\": \"text\", \"copy_to\": \"semantic_field\"},\n",
    "            \"content\": {\"type\": \"text\", \"copy_to\": \"semantic_field\"},\n",
    "            \"category\": {\"type\": \"keyword\"},\n",
    "            \"published_date\": {\"type\": \"date\"},\n",
    "            \"semantic_field\": {\n",
    "                \"type\": \"semantic_text\",\n",
    "                \"inference_id\": INFERENCE_ENDPOINT_ID,\n",
    "            },\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# Only create the index if it doesn't exist\n",
    "if not es.indices.exists(index=INDEX_NAME):\n",
    "    response = es.indices.create(index=INDEX_NAME, body=index_mappings)\n",
    "    print(f\"Created index: {INDEX_NAME}\")\n",
    "    print(json.dumps(response.body, indent=2))\n",
    "else:\n",
    "    print(f\"Index '{INDEX_NAME}' already exists, skipping creation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c64f0715",
   "metadata": {},
   "source": [
    "## Ingest Sample Data\n",
    "\n",
    "### Best Practice: Use Bulk Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2813a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from elasticsearch import helpers\n",
    "\n",
    "\n",
    "def build_data(json_file, index_name):\n",
    "    \"\"\"Generator function to yield documents for bulk indexing.\"\"\"\n",
    "    with open(json_file, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    for doc in data:\n",
    "        yield {\"_index\": index_name, \"_source\": doc}\n",
    "\n",
    "\n",
    "# Bulk index the documents from JSON file\n",
    "try:\n",
    "    success, failed = helpers.bulk(\n",
    "        es,\n",
    "        build_data(\"dataset.json\", INDEX_NAME),\n",
    "    )\n",
    "    print(f\"{success} documents indexed successfully\")\n",
    "\n",
    "    if failed:\n",
    "        print(f\"Errors: {failed}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af3cfa1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check document count\n",
    "count = es.count(index=INDEX_NAME)\n",
    "print(f\"Total documents in index: {count.body['count']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e838807",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "## Semantic Search\n",
    "\n",
    "### Best Practice: Use `match` Query on `semantic_text` Fields\n",
    "The `match` query automatically detects `semantic_text` fields and handles embedding generation for your search query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f3eb7a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def semantic_search(query: str, size: int = 3):\n",
    "    \"\"\"Perform semantic search on the tech-articles index.\"\"\"\n",
    "    response = es.search(\n",
    "        index=INDEX_NAME,\n",
    "        body={\n",
    "            \"query\": {\"match\": {\"semantic_field\": {\"query\": query}}},\n",
    "            \"size\": size,\n",
    "            \"_source\": [\"title\", \"category\", \"content\"],\n",
    "        },\n",
    "    )\n",
    "\n",
    "    print(f\"Query: '{query}'\\n\")\n",
    "    print(f\"Found {response.body['hits']['total']['value']} results:\\n\")\n",
    "\n",
    "    for hit in response.body[\"hits\"][\"hits\"]:\n",
    "        print(f\"Score: {hit['_score']:.4f}\")\n",
    "        print(f\"Title: {hit['_source']['title']}\")\n",
    "        print(f\"Category: {hit['_source']['category']}\")\n",
    "        print(f\"Content: {hit['_source']['content'][:150]}...\\n\")\n",
    "\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a89e3b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test semantic search\n",
    "semantic_search(\"How do I implement similarity search in my application?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed3b3e51",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "## Hybrid Search (BM25 + Semantic)\n",
    "\n",
    "### Best Practice: Combine Lexical and Semantic Search\n",
    "Hybrid search gives you the best of both worlds - exact keyword matching and semantic understanding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0c20618",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hybrid_search(query: str, size: int = 3):\n",
    "    \"\"\"Perform hybrid search combining BM25 and semantic search.\"\"\"\n",
    "    response = es.search(\n",
    "        index=INDEX_NAME,\n",
    "        body={\n",
    "            \"retriever\": {\n",
    "                \"rrf\": {\n",
    "                    \"retrievers\": [\n",
    "                        {\n",
    "                            \"standard\": {\n",
    "                                \"query\": {\n",
    "                                    \"multi_match\": {\n",
    "                                        \"query\": query,\n",
    "                                        \"fields\": [\n",
    "                                            \"title^2\",\n",
    "                                            \"content\",\n",
    "                                        ],  # BM25 on original text fields\n",
    "                                    }\n",
    "                                }\n",
    "                            }\n",
    "                        },\n",
    "                        {\n",
    "                            \"standard\": {\n",
    "                                \"query\": {\"match\": {\"semantic_field\": {\"query\": query}}}\n",
    "                            }\n",
    "                        },\n",
    "                    ],\n",
    "                    \"rank_window_size\": 50,\n",
    "                    \"rank_constant\": 20,\n",
    "                }\n",
    "            },\n",
    "            \"size\": size,\n",
    "            \"_source\": [\"title\", \"category\"],\n",
    "        },\n",
    "    )\n",
    "\n",
    "    print(f\"Hybrid Search Query: '{query}'\\n\")\n",
    "\n",
    "    for hit in response.body[\"hits\"][\"hits\"]:\n",
    "        print(\n",
    "            f\"Score: {hit['_score']:.4f} | {hit['_source']['title']} [{hit['_source']['category']}]\"\n",
    "        )\n",
    "\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfdcb17d",
   "metadata": {},
   "outputs": [],
   "source": [
    "hybrid_search(\"What are the best practices for semantic search in Elasticsearch?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01b3a2a1",
   "metadata": {},
   "source": [
    "## Step 6: Define a Search Workflow\n",
    "\n",
    "**Elastic Workflows** is an automation engine built into Elasticsearch that orchestrates multi-step processes using YAML.\n",
    "\n",
    "### Why Workflows?\n",
    "- Automate repeatable search and data processing tasks\n",
    "- Chain Elasticsearch operations with flow control (`if`, `foreach`)\n",
    "- Serve as reliable, auditable \"hands\" for AI agents\n",
    "\n",
    "> **Note:** Workflows is disabled by default. Enable it in Kibana Advanced Settings `Stack Management > Advanced Settings > workflows:ui:enabled`.\n",
    "> Workflows are created and managed from the Kibana UI — paste the YAML below into the editor to create this workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bf1b67c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "name: Hacker News Digest\n",
    "description: >\n",
    "  Fetches the latest top stories from the Hacker News public API, indexes them\n",
    "  into Elasticsearch with semantic embeddings, then asks the AI agent to\n",
    "  summarize the key themes from the freshly ingested content.\n",
    "enabled: true\n",
    "tags: [\"ingestion\", \"hacker-news\", \"agent\", \"demo\"]\n",
    "\n",
    "consts:\n",
    "  indexName: tech-articles\n",
    "  hnApiBase: \"https://hacker-news.firebaseio.com/v0\"\n",
    "  agentId: tech-articles-assistant\n",
    "\n",
    "triggers:\n",
    "  - type: manual\n",
    "\n",
    "steps:\n",
    "  # Step 1: Fetch top story IDs from the Hacker News public API (no auth required)\n",
    "  - name: fetch_top_stories\n",
    "    type: http\n",
    "    with:\n",
    "      url: \"{{ consts.hnApiBase }}/topstories.json\"\n",
    "      method: GET\n",
    "\n",
    "  # Step 2: For each story ID, fetch details and index into Elasticsearch.\n",
    "  - name: process_stories\n",
    "    type: foreach\n",
    "    foreach: \"${{ steps.fetch_top_stories.output.data | slice: 0, 5 }}\"\n",
    "    steps:\n",
    "      - name: fetch_story_detail\n",
    "        type: http\n",
    "        with:\n",
    "          url: \"{{ consts.hnApiBase }}/item/{{ foreach.item }}.json\"\n",
    "          method: GET\n",
    "\n",
    "      - name: index_story\n",
    "        type: elasticsearch.request\n",
    "        with:\n",
    "          method: POST\n",
    "          path: \"/{{ consts.indexName }}/_doc\"\n",
    "          body:\n",
    "            title: \"{{ steps.fetch_story_detail.output.data.title }}\"\n",
    "            content: \"{{ steps.fetch_story_detail.output.data.text | default: steps.fetch_story_detail.output.data.title }}\"\n",
    "            category: \"hacker-news\"\n",
    "            url: \"{{ steps.fetch_story_detail.output.data.url }}\"\n",
    "\n",
    "  # Step 3: Ask the agent to summarize the freshly indexed stories.\n",
    "  - name: ask_agent\n",
    "    type: ai.agent\n",
    "    with:\n",
    "      agent_id: \"{{ consts.agentId }}\"\n",
    "      message: \"What are the main themes and topics from the latest Hacker News stories?\"\n",
    "\n",
    "  - name: log_summary\n",
    "    type: console\n",
    "    with:\n",
    "      message: \"{{ steps.ask_agent.output }}\"\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c8a125e",
   "metadata": {},
   "source": [
    "### Results of Workflow Creation\n",
    "\n",
    "![image.png](assets/image.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ed5f026",
   "metadata": {},
   "source": [
    "## Step 7: Create an AI Agent with Agent Builder\n",
    "\n",
    "Agent Builder uses LLMs to power agent reasoning and decision-making.\n",
    "\n",
    "### Agents + Workflows\n",
    "Agents and Workflows are complementary: workflows handle deterministic, repeatable tasks reliably, while agents provide reasoning for open-ended questions. An agent can invoke a workflow as a tool via MCP, delegating concrete execution while it focuses on understanding the user's intent.\n",
    "\n",
    "### Default vs Custom LLM\n",
    "- **Elastic Managed LLM** (default): Available out-of-the-box on Elastic Cloud. No configuration or API keys needed.\n",
    "- **Custom LLM**: You can configure third-party providers (OpenAI, Azure, Anthropic, etc.) using connectors.\n",
    "\n",
    "### SSL Certificate Verification\n",
    "For production environments, use `verify=True` when making HTTPS requests:\n",
    "- **Elastic Cloud**: Certificates are valid by default, no additional configuration needed.\n",
    "- **Self-managed**: You may need to provide the CA certificate path (e.g., `verify=\"/path/to/ca.crt\"`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bca0c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {\n",
    "    \"kbn-xsrf\": \"true\",\n",
    "    \"Authorization\": f\"ApiKey {ELASTIC_API_KEY}\",\n",
    "    \"Content-Type\": \"application/json\",\n",
    "}\n",
    "\n",
    "agent_payload = {\n",
    "    \"id\": \"tech-articles-assistant\",\n",
    "    \"name\": \"Tech Articles Assistant\",\n",
    "    \"description\": \"An AI assistant that helps users find information about technology topics from our knowledge base.\",\n",
    "    \"configuration\": {\n",
    "        # Uses Elastic Managed LLM by default — no connector_id needed\n",
    "        \"tools\": [{\"tool_ids\": [\"platform.core.search\", \"platform.core.execute_esql\"]}],\n",
    "        \"instructions\": f\"\"\"You are a helpful assistant that answers questions about technology topics.\n",
    "\n",
    "Use the search tool to find relevant articles from the '{INDEX_NAME}' index.\n",
    "When searching, prefer semantic search for natural language questions.\n",
    "Always cite the article titles when providing information.\n",
    "If you cannot find relevant information, say so clearly.\"\"\",\n",
    "    },\n",
    "}\n",
    "\n",
    "response = requests.post(\n",
    "    f\"{KIBANA_URL}/api/agent_builder/agents\",\n",
    "    headers=headers,\n",
    "    json=agent_payload,\n",
    "    verify=True,\n",
    ")\n",
    "\n",
    "if response.status_code == 200:\n",
    "    agent_data = response.json()\n",
    "    agent_id = agent_data.get(\"id\")\n",
    "    print(f\"Created agent: {agent_id}\")\n",
    "    print(json.dumps(agent_data, indent=2))\n",
    "else:\n",
    "    print(f\"Error creating agent: {response.text}\")\n",
    "    agent_id = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "644c4ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chat with the agent\n",
    "def chat_with_agent(agent_id: str, message: str):\n",
    "    \"\"\"Send a message to the agent and get a response.\"\"\"\n",
    "    chat_payload = {\"input\": message, \"agent_id\": agent_id}\n",
    "\n",
    "    response = requests.post(\n",
    "        f\"{KIBANA_URL}/api/agent_builder/converse\",\n",
    "        headers=headers,\n",
    "        json=chat_payload,\n",
    "        verify=True,\n",
    "    )\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        return response.json()\n",
    "    else:\n",
    "        return {\"error\": response.text, \"status_code\": response.status_code}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f01b00df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example conversation\n",
    "if agent_id:\n",
    "    result = chat_with_agent(\n",
    "        agent_id, \"What are the best practices for building RAG applications?\"\n",
    "    )\n",
    "    print(json.dumps(result, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9603c292",
   "metadata": {},
   "outputs": [],
   "source": [
    "# es.indices.delete(index=INDEX_NAME)\n",
    "# es.inference.delete(inference_id=INFERENCE_ENDPOINT_ID)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "encoding": "# -*- coding: utf-8 -*-",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
