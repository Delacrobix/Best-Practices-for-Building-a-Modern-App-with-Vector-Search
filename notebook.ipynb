{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Best Practices for Building a Modern App with Vector Search\n",
    "\n",
    "This notebook demonstrates how to build a modern LLM-powered application using:\n",
    "\n",
    "- **Jina Embeddings v3** via Elastic Inference Service (EIS) - GPU-accelerated multilingual embeddings\n",
    "- **Elasticsearch 9.3+** for vector storage and semantic search\n",
    "- **Agent Builder** for creating AI agents that can query your data\n",
    "\n",
    "## What You'll Learn\n",
    "\n",
    "1. Setting up inference endpoints for embeddings\n",
    "2. Creating optimized indices for vector search\n",
    "3. Ingesting data with automatic embedding generation\n",
    "4. Performing semantic searches\n",
    "5. Building an AI agent with Agent Builder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.3\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m26.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Install required packages\n",
    "!pip install elasticsearch requests dotenv -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import requests\n",
    "from elasticsearch import Elasticsearch\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# Elasticsearch configuration\n",
    "ELASTICSEARCH_URL = os.getenv(\"ELASTICSEARCH_URL\")\n",
    "ELASTIC_API_KEY = os.getenv(\"ELASTICSEARCH_API_KEY\")\n",
    "KIBANA_URL = os.getenv(\"KIBANA_URL\")\n",
    "\n",
    "# Initialize Elasticsearch client\n",
    "es = Elasticsearch(ELASTICSEARCH_URL, api_key=ELASTIC_API_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Create Inference Endpoint for Embeddings\n",
    "\n",
    "We'll use **Jina Embeddings v3** through Elastic Inference Service (EIS). This model:\n",
    "\n",
    "- Is multilingual out of the box\n",
    "- Runs on Elastic's GPU infrastructure (no ML nodes needed)\n",
    "\n",
    "### Best Practice: Use EIS for Production Workloads\n",
    "EIS eliminates the need to manage ML infrastructure while providing GPU-accelerated performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created inference endpoint: jina-embeddings-v3\n",
      "{\n",
      "  \"inference_id\": \"jina-embeddings-v3\",\n",
      "  \"task_type\": \"text_embedding\",\n",
      "  \"service\": \"elastic\",\n",
      "  \"service_settings\": {\n",
      "    \"model_id\": \"jina-embeddings-v3\",\n",
      "    \"similarity\": \"cosine\",\n",
      "    \"dimensions\": 1024\n",
      "  },\n",
      "  \"chunking_settings\": {\n",
      "    \"strategy\": \"sentence\",\n",
      "    \"max_chunk_size\": 250,\n",
      "    \"sentence_overlap\": 1\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "INFERENCE_ENDPOINT_ID = \"jina-embeddings-v3\"\n",
    "\n",
    "# Create the inference endpoint for Jina Embeddings v3\n",
    "inference_config = {\n",
    "    \"service\": \"elastic\",\n",
    "    \"service_settings\": {\"model_id\": \"jina-embeddings-v3\"},\n",
    "}\n",
    "\n",
    "try:\n",
    "    response = es.inference.put(\n",
    "        inference_id=INFERENCE_ENDPOINT_ID,\n",
    "        task_type=\"text_embedding\",\n",
    "        body=inference_config,\n",
    "    )\n",
    "\n",
    "    print(f\"Created inference endpoint: {INFERENCE_ENDPOINT_ID}\")\n",
    "    print(json.dumps(response.body, indent=2))\n",
    "except Exception as e:\n",
    "    print(f\"Endpoint may already exist or error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding dimensions: 1024\n",
      "First 5 values: [0.09668593, -0.0195286, 0.03599555, -0.04717219, 0.07873663]\n"
     ]
    }
   ],
   "source": [
    "# Test the inference endpoint\n",
    "test_response = es.inference.inference(\n",
    "    inference_id=INFERENCE_ENDPOINT_ID,\n",
    "    body={\n",
    "        \"input\": \"Elasticsearch is a distributed search and analytics engine.\",\n",
    "        \"input_type\": \"ingest\",\n",
    "    },\n",
    ")\n",
    "\n",
    "embedding = test_response.body[\"text_embedding\"][0][\"embedding\"]\n",
    "print(f\"Embedding dimensions: {len(embedding)}\")\n",
    "print(f\"First 5 values: {embedding[:5]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Create an Optimized Index for Vector Search\n",
    "\n",
    "### Best Practices for Index Design:\n",
    "1. **Use `semantic_text` field type** - Automatically handles chunking and embedding generation\n",
    "2. **Use `copy_to` pattern** - Keep original fields for BM25 and copy content to a dedicated semantic field\n",
    "3. **Consider field lengths** - Jina v3 performs optimally with 2048-4096 tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index 'tech-articles' already exists, skipping creation\n"
     ]
    }
   ],
   "source": [
    "INDEX_NAME = \"tech-articles\"\n",
    "\n",
    "# Create index with semantic_text field using copy_to pattern\n",
    "# Best Practice: Keep original fields for BM25 search and use copy_to for semantic search\n",
    "index_mappings = {\n",
    "    \"mappings\": {\n",
    "        \"properties\": {\n",
    "            \"title\": {\"type\": \"text\", \"copy_to\": \"semantic_field\"},\n",
    "            \"content\": {\"type\": \"text\", \"copy_to\": \"semantic_field\"},\n",
    "            \"category\": {\"type\": \"keyword\"},\n",
    "            \"published_date\": {\"type\": \"date\"},\n",
    "            \"semantic_field\": {\n",
    "                \"type\": \"semantic_text\",\n",
    "                \"inference_id\": INFERENCE_ENDPOINT_ID,\n",
    "            },\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# Only create the index if it doesn't exist\n",
    "if not es.indices.exists(index=INDEX_NAME):\n",
    "    response = es.indices.create(index=INDEX_NAME, body=index_mappings)\n",
    "    print(f\"Created index: {INDEX_NAME}\")\n",
    "    print(json.dumps(response.body, indent=2))\n",
    "else:\n",
    "    print(f\"Index '{INDEX_NAME}' already exists, skipping creation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Ingest Sample Data\n",
    "\n",
    "### Best Practice: Use Bulk Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 documents indexed successfully\n"
     ]
    }
   ],
   "source": [
    "from elasticsearch import helpers\n",
    "\n",
    "\n",
    "def build_data(json_file, index_name):\n",
    "    \"\"\"Generator function to yield documents for bulk indexing.\"\"\"\n",
    "    with open(json_file, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    for doc in data:\n",
    "        yield {\"_index\": index_name, \"_source\": doc}\n",
    "\n",
    "\n",
    "# Bulk index the documents from JSON file\n",
    "try:\n",
    "    success, failed = helpers.bulk(\n",
    "        es,\n",
    "        build_data(\"dataset.json\", INDEX_NAME),\n",
    "    )\n",
    "    print(f\"{success} documents indexed successfully\")\n",
    "\n",
    "    if failed:\n",
    "        print(f\"Errors: {failed}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total documents in index: 5\n"
     ]
    }
   ],
   "source": [
    "# Check document count\n",
    "count = es.count(index=INDEX_NAME)\n",
    "print(f\"Total documents in index: {count.body['count']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Semantic Search\n",
    "\n",
    "### Best Practice: Use `semantic` Query Type\n",
    "The `semantic` query automatically handles embedding generation for your search query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def semantic_search(query: str, size: int = 3):\n",
    "    \"\"\"Perform semantic search on the tech-articles index.\"\"\"\n",
    "    response = es.search(\n",
    "        index=INDEX_NAME,\n",
    "        body={\n",
    "            \"query\": {\n",
    "                \"semantic\": {\n",
    "                    \"field\": \"semantic_field\",  # Use the dedicated semantic field\n",
    "                    \"query\": query,\n",
    "                }\n",
    "            },\n",
    "            \"size\": size,\n",
    "            \"_source\": [\"title\", \"category\", \"content\"],\n",
    "        },\n",
    "    )\n",
    "\n",
    "    print(f\"Query: '{query}'\\n\")\n",
    "    print(f\"Found {response.body['hits']['total']['value']} results:\\n\")\n",
    "\n",
    "    for hit in response.body[\"hits\"][\"hits\"]:\n",
    "        print(f\"Score: {hit['_score']:.4f}\")\n",
    "        print(f\"Title: {hit['_source']['title']}\")\n",
    "        print(f\"Category: {hit['_source']['category']}\")\n",
    "        print(f\"Content: {hit['_source']['content'][:150]}...\\n\")\n",
    "\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: 'How do I implement similarity search in my application?'\n",
      "\n",
      "Found 5 results:\n",
      "\n",
      "Score: 0.6704\n",
      "Title: Introduction to Vector Databases\n",
      "Category: databases\n",
      "Content: Vector databases are specialized systems designed to store and query high-dimensional vectors efficiently. They enable similarity search, which is fun...\n",
      "\n",
      "Score: 0.6694\n",
      "Title: Building RAG Applications with Elasticsearch\n",
      "Category: ai\n",
      "Content: Retrieval-Augmented Generation (RAG) combines the power of large language models with external knowledge retrieval. Elasticsearch provides an excellen...\n",
      "\n",
      "Score: 0.6445\n",
      "Title: Embeddings: The Foundation of Semantic Search\n",
      "Category: ai\n",
      "Content: Embeddings are numerical representations of text that capture semantic meaning. Modern embedding models like Jina v3 can process text in multiple lang...\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ObjectApiResponse({'took': 418, 'timed_out': False, '_shards': {'total': 1, 'successful': 1, 'skipped': 0, 'failed': 0}, 'hits': {'total': {'value': 5, 'relation': 'eq'}, 'max_score': 0.67035043, 'hits': [{'_index': 'tech-articles', '_id': 'pSDSLpwBTUn0vNv4bwT6', '_score': 0.67035043, '_source': {'title': 'Introduction to Vector Databases', 'content': 'Vector databases are specialized systems designed to store and query high-dimensional vectors efficiently. They enable similarity search, which is fundamental for AI applications like recommendation systems, image search, and semantic text search. Unlike traditional databases that use exact matching, vector databases find the most similar items based on distance metrics like cosine similarity or Euclidean distance.', 'category': 'databases'}}, {'_index': 'tech-articles', '_id': 'piDSLpwBTUn0vNv4bwT6', '_score': 0.6693985, '_source': {'title': 'Building RAG Applications with Elasticsearch', 'content': 'Retrieval-Augmented Generation (RAG) combines the power of large language models with external knowledge retrieval. Elasticsearch provides an excellent foundation for RAG applications by offering hybrid search capabilities that combine traditional BM25 text matching with semantic vector search. This hybrid approach ensures both keyword relevance and semantic understanding in your search results.', 'category': 'ai'}}, {'_index': 'tech-articles', '_id': 'pyDSLpwBTUn0vNv4bwT6', '_score': 0.64447546, '_source': {'title': 'Embeddings: The Foundation of Semantic Search', 'content': 'Embeddings are numerical representations of text that capture semantic meaning. Modern embedding models like Jina v3 can process text in multiple languages and produce high-quality vectors that preserve semantic relationships. The key to effective semantic search is choosing the right embedding model for your use case and ensuring your text is properly preprocessed before embedding generation.', 'category': 'ai'}}]}})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test semantic search\n",
    "semantic_search(\"How do I implement similarity search in my application?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Hybrid Search (BM25 + Semantic)\n",
    "\n",
    "### Best Practice: Combine Lexical and Semantic Search\n",
    "Hybrid search gives you the best of both worlds - exact keyword matching and semantic understanding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hybrid_search(query: str, size: int = 3):\n",
    "    \"\"\"Perform hybrid search combining BM25 and semantic search.\"\"\"\n",
    "    response = es.search(\n",
    "        index=INDEX_NAME,\n",
    "        body={\n",
    "            \"retriever\": {\n",
    "                \"rrf\": {\n",
    "                    \"retrievers\": [\n",
    "                        {\n",
    "                            \"standard\": {\n",
    "                                \"query\": {\n",
    "                                    \"multi_match\": {\n",
    "                                        \"query\": query,\n",
    "                                        \"fields\": [\n",
    "                                            \"title^2\",\n",
    "                                            \"content\",\n",
    "                                        ],  # BM25 on original fields\n",
    "                                    }\n",
    "                                }\n",
    "                            }\n",
    "                        },\n",
    "                        {\n",
    "                            \"standard\": {\n",
    "                                \"query\": {\n",
    "                                    \"semantic\": {\n",
    "                                        \"field\": \"semantic_field\",  # Semantic on dedicated field\n",
    "                                        \"query\": query,\n",
    "                                    }\n",
    "                                }\n",
    "                            }\n",
    "                        },\n",
    "                    ],\n",
    "                    \"rank_window_size\": 50,\n",
    "                    \"rank_constant\": 20,\n",
    "                }\n",
    "            },\n",
    "            \"size\": size,\n",
    "            \"_source\": [\"title\", \"category\"],\n",
    "        },\n",
    "    )\n",
    "\n",
    "    print(f\"Hybrid Search Query: '{query}'\\n\")\n",
    "\n",
    "    for hit in response.body[\"hits\"][\"hits\"]:\n",
    "        print(\n",
    "            f\"Score: {hit['_score']:.4f} | {hit['_source']['title']} [{hit['_source']['category']}]\"\n",
    "        )\n",
    "\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hybrid Search Query: 'Elasticsearch vector search production'\n",
      "\n",
      "Score: 0.0952 | Scaling Elasticsearch for Production [infrastructure]\n",
      "Score: 0.0871 | Introduction to Vector Databases [databases]\n",
      "Score: 0.0871 | Building RAG Applications with Elasticsearch [ai]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ObjectApiResponse({'took': 293, 'timed_out': False, '_shards': {'total': 1, 'successful': 1, 'skipped': 0, 'failed': 0}, 'hits': {'total': {'value': 5, 'relation': 'eq'}, 'max_score': 0.0952381, 'hits': [{'_index': 'tech-articles', '_id': 'qCDSLpwBTUn0vNv4bwT6', '_score': 0.0952381, '_source': {'title': 'Scaling Elasticsearch for Production', 'category': 'infrastructure'}}, {'_index': 'tech-articles', '_id': 'pSDSLpwBTUn0vNv4bwT6', '_score': 0.08712122, '_source': {'title': 'Introduction to Vector Databases', 'category': 'databases'}}, {'_index': 'tech-articles', '_id': 'piDSLpwBTUn0vNv4bwT6', '_score': 0.08712122, '_source': {'title': 'Building RAG Applications with Elasticsearch', 'category': 'ai'}}]}})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test hybrid search\n",
    "hybrid_search(\"Elasticsearch vector search production\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Create an AI Agent with Agent Builder\n",
    "\n",
    "Agent Builder uses LLMs to power agent reasoning and decision-making.\n",
    "\n",
    "### Default vs Custom LLM\n",
    "- **Elastic Managed LLM** (default): Available out-of-the-box on Elastic Cloud. No configuration or API keys needed.\n",
    "- **Custom LLM**: You can configure third-party providers (OpenAI, Azure, Anthropic, etc.) using connectors.\n",
    "\n",
    "In this example, we'll use the default Elastic Managed LLM for simplicity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Create an AI Agent with Agent Builder\n",
    "\n",
    "Agent Builder uses LLMs to power agent reasoning and decision-making.\n",
    "\n",
    "### Default vs Custom LLM\n",
    "- **Elastic Managed LLM** (default): Available out-of-the-box on Elastic Cloud. No configuration or API keys needed.\n",
    "- **Custom LLM**: You can configure third-party providers (OpenAI, Azure, Anthropic, etc.) using connectors.\n",
    "\n",
    "### SSL Certificate Verification\n",
    "For production environments, use `verify=True` when making HTTPS requests:\n",
    "- **Elastic Cloud**: Certificates are valid by default, no additional configuration needed.\n",
    "- **Self-managed**: You may need to provide the CA certificate path (e.g., `verify=\"/path/to/ca.crt\"`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error creating agent: {\"statusCode\":400,\"error\":\"Bad Request\",\"message\":\"Agent with id tech-articles-assistant already exists\",\"attributes\":{}}\n"
     ]
    }
   ],
   "source": [
    "# Create an Agent using the default Elastic Managed LLM\n",
    "\n",
    "headers = {\n",
    "    \"kbn-xsrf\": \"true\",\n",
    "    \"Authorization\": f\"ApiKey {ELASTIC_API_KEY}\",\n",
    "    \"Content-Type\": \"application/json\",\n",
    "}\n",
    "\n",
    "agent_payload = {\n",
    "    \"id\": \"tech-articles-assistant\",\n",
    "    \"name\": \"Tech Articles Assistant\",\n",
    "    \"description\": \"An AI assistant that helps users find information about technology topics from our knowledge base.\",\n",
    "    \"configuration\": {\n",
    "        \"tools\": [{\"tool_ids\": [\"platform.core.search\", \"platform.core.execute_esql\"]}],\n",
    "        \"instructions\": f\"\"\"You are a helpful assistant that answers questions about technology topics.\n",
    "\n",
    "Use the search tool to find relevant articles from the '{INDEX_NAME}' index.\n",
    "When searching, prefer semantic search for natural language questions.\n",
    "Always cite the article titles when providing information.\n",
    "If you cannot find relevant information, say so clearly.\"\"\",\n",
    "    },\n",
    "}\n",
    "\n",
    "response = requests.post(\n",
    "    f\"{KIBANA_URL}/api/agent_builder/agents\",\n",
    "    headers=headers,\n",
    "    json=agent_payload,\n",
    "    verify=True,\n",
    ")\n",
    "\n",
    "if response.status_code == 200:\n",
    "    agent_data = response.json()\n",
    "    agent_id = agent_data.get(\"id\")\n",
    "    print(f\"Created agent: {agent_id}\")\n",
    "    print(json.dumps(agent_data, indent=2))\n",
    "else:\n",
    "    print(f\"Error creating agent: {response.text}\")\n",
    "    agent_id = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chat with the agent\n",
    "def chat_with_agent(agent_id: str, message: str):\n",
    "    \"\"\"Send a message to the agent and get a response.\"\"\"\n",
    "    chat_payload = {\"input\": message, \"agent_id\": agent_id}\n",
    "\n",
    "    response = requests.post(\n",
    "        f\"{KIBANA_URL}/api/agent_builder/converse\",\n",
    "        headers=headers,\n",
    "        json=chat_payload,\n",
    "        verify=True,\n",
    "    )\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        return response.json()\n",
    "    else:\n",
    "        return {\"error\": response.text, \"status_code\": response.status_code}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"conversation_id\": \"e0611691-6f5f-43bd-afa1-af498164c114\",\n",
      "  \"steps\": [\n",
      "    {\n",
      "      \"type\": \"reasoning\",\n",
      "      \"reasoning\": \"The user is asking about best practices for RAG (Retrieval Augmented Generation) applications, which is a technical topic. I should search for relevant articles that discuss this topic.\"\n",
      "    },\n",
      "    {\n",
      "      \"type\": \"tool_call\",\n",
      "      \"tool_call_id\": \"tooluse_zGmCp5mmFIwGCDu4mE2hjO\",\n",
      "      \"tool_id\": \"platform.core.search\",\n",
      "      \"progression\": [\n",
      "        {\n",
      "          \"message\": \"Identifying the most relevant data source\"\n",
      "        },\n",
      "        {\n",
      "          \"message\": \"Analyzing strategy to search against \\\"tech-articles\\\"\"\n",
      "        },\n",
      "        {\n",
      "          \"message\": \"Searching documents for \\\"best practices for building RAG applications retrieval augmented generation\\\"\"\n",
      "        }\n",
      "      ],\n",
      "      \"params\": {\n",
      "        \"query\": \"best practices for building RAG applications retrieval augmented generation\"\n",
      "      },\n",
      "      \"results\": []\n",
      "    },\n",
      "    {\n",
      "      \"type\": \"reasoning\",\n",
      "      \"reasoning\": \"The previous search returned no results. Let me try a broader search query about RAG to find relevant articles.\"\n",
      "    },\n",
      "    {\n",
      "      \"type\": \"tool_call\",\n",
      "      \"tool_call_id\": \"tooluse_kicDJG1WZHEcwsnFwcdDqa\",\n",
      "      \"tool_id\": \"platform.core.search\",\n",
      "      \"progression\": [\n",
      "        {\n",
      "          \"message\": \"Identifying the most relevant data source\"\n",
      "        },\n",
      "        {\n",
      "          \"message\": \"Analyzing strategy to search against \\\"tech-articles\\\"\"\n",
      "        },\n",
      "        {\n",
      "          \"message\": \"Searching documents for \\\"RAG retrieval augmented generation\\\"\"\n",
      "        }\n",
      "      ],\n",
      "      \"params\": {\n",
      "        \"query\": \"RAG retrieval augmented generation\"\n",
      "      },\n",
      "      \"results\": []\n",
      "    },\n",
      "    {\n",
      "      \"type\": \"reasoning\",\n",
      "      \"reasoning\": \"Previous searches for RAG specifically returned no results. Let me try a broader search about retrieval systems for AI applications to see if there are related articles.\"\n",
      "    },\n",
      "    {\n",
      "      \"type\": \"tool_call\",\n",
      "      \"tool_call_id\": \"tooluse_TW95Yx1DhpWxXJyGYQuWxH\",\n",
      "      \"tool_id\": \"platform.core.search\",\n",
      "      \"progression\": [\n",
      "        {\n",
      "          \"message\": \"Identifying the most relevant data source\"\n",
      "        },\n",
      "        {\n",
      "          \"message\": \"Analyzing strategy to search against \\\"tech-articles\\\"\"\n",
      "        },\n",
      "        {\n",
      "          \"message\": \"Searching documents for \\\"retrieval systems for AI applications best practices\\\"\"\n",
      "        }\n",
      "      ],\n",
      "      \"params\": {\n",
      "        \"query\": \"retrieval systems for AI applications best practices\"\n",
      "      },\n",
      "      \"results\": []\n",
      "    },\n",
      "    {\n",
      "      \"type\": \"reasoning\",\n",
      "      \"reasoning\": \"Let me try searching for articles about AI and search systems more broadly, as they might contain information relevant to RAG applications.\"\n",
      "    },\n",
      "    {\n",
      "      \"type\": \"tool_call\",\n",
      "      \"tool_call_id\": \"tooluse_A19XhtGPGZbwAYGcYkhI4S\",\n",
      "      \"tool_id\": \"platform.core.search\",\n",
      "      \"progression\": [\n",
      "        {\n",
      "          \"message\": \"Identifying the most relevant data source\"\n",
      "        },\n",
      "        {\n",
      "          \"message\": \"Analyzing strategy to search against \\\"tech-articles\\\"\"\n",
      "        },\n",
      "        {\n",
      "          \"message\": \"Searching documents for \\\"AI search systems semantic search vector search\\\"\"\n",
      "        }\n",
      "      ],\n",
      "      \"params\": {\n",
      "        \"query\": \"AI search systems semantic search vector search\"\n",
      "      },\n",
      "      \"results\": []\n",
      "    },\n",
      "    {\n",
      "      \"type\": \"reasoning\",\n",
      "      \"reasoning\": \"Let me try searching for articles about generative AI applications, which might include information about RAG.\"\n",
      "    },\n",
      "    {\n",
      "      \"type\": \"tool_call\",\n",
      "      \"tool_call_id\": \"tooluse_WV38Kx692owrUYgYL2qeij\",\n",
      "      \"tool_id\": \"platform.core.search\",\n",
      "      \"progression\": [\n",
      "        {\n",
      "          \"message\": \"Identifying the most relevant data source\"\n",
      "        },\n",
      "        {\n",
      "          \"message\": \"Analyzing strategy to search against \\\"tech-articles\\\"\"\n",
      "        },\n",
      "        {\n",
      "          \"message\": \"Searching documents for \\\"generative AI applications\\\"\"\n",
      "        }\n",
      "      ],\n",
      "      \"params\": {\n",
      "        \"query\": \"generative AI applications\",\n",
      "        \"index\": \"tech-articles\"\n",
      "      },\n",
      "      \"results\": []\n",
      "    }\n",
      "  ],\n",
      "  \"started_at\": \"2026-02-05T18:56:19.925Z\",\n",
      "  \"time_to_first_token\": 39228,\n",
      "  \"time_to_last_token\": 40363,\n",
      "  \"model_usage\": {\n",
      "    \"connector_id\": \"Anthropic-Claude-Sonnet-3-7\",\n",
      "    \"llm_calls\": 16,\n",
      "    \"input_tokens\": 31187,\n",
      "    \"output_tokens\": 1551,\n",
      "    \"model\": \"rainbow-sprinkles\"\n",
      "  },\n",
      "  \"response\": {\n",
      "    \"message\": \"I don't have specific information about best practices for building RAG (Retrieval Augmented Generation) applications in our current knowledge base. \\n\\nRAG is an important approach that combines retrieval systems with generative AI to produce more accurate, grounded responses. However, I can't provide detailed best practices without access to reliable sources on this topic.\\n\\nIf you're interested in learning about RAG applications, you might want to consider:\\n\\n1. Exploring official documentation from vector database providers\\n2. Reviewing technical papers on RAG architectures\\n3. Looking into open-source RAG implementations\\n\\nWould you like me to help you with a different topic related to AI or search technologies?\"\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Example conversation\n",
    "if agent_id:\n",
    "    result = chat_with_agent(\n",
    "        agent_id, \"What are the best practices for building RAG applications?\"\n",
    "    )\n",
    "    print(json.dumps(result, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# es.indices.delete(index=INDEX_NAME)\n",
    "# es.inference.delete(inference_id=INFERENCE_ENDPOINT_ID)\n",
    "# print(\"Cleanup complete\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
